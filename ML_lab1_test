# lab1_test.py  —— 运行目录：.../week_1_2
import os
import numpy as np
import matplotlib
matplotlib.use("Agg")  # headless 保存图片
import matplotlib.pyplot as plt
import xml.etree.ElementTree as ET

from simulation_and_control import (
    pb, MotorCommands, PinWrapper, feedback_lin_ctrl, SinusoidalReference
)

# ------------------------ URDF helpers ------------------------
def rpy_to_R(roll, pitch, yaw):
    cr, sr = np.cos(roll), np.sin(roll)
    cp, sp = np.cos(pitch), np.sin(pitch)
    cy, sy = np.cos(yaw), np.sin(yaw)
    Rz = np.array([[cy, -sy, 0],[sy, cy, 0],[0, 0, 1]])
    Ry = np.array([[cp, 0, sp],[0, 1, 0],[-sp, 0, cp]])
    Rx = np.array([[1, 0, 0],[0, cr, -sr],[0, sr, cr]])
    return Rz @ Ry @ Rx  # Z-Y-X fixed-axis

def extract_link10_from_urdf(urdf_path, link_name):
    """
    Return [m, m*cx, m*cy, m*cz, Ixx, Ixy, Ixz, Iyy, Iyz, Izz] in the LINK frame.
    Assumes <inertial><origin> is at COM (URDF convention).
    """
    tree = ET.parse(urdf_path)
    root = tree.getroot()
    link = None
    for lk in root.findall('link'):
        if lk.get('name') == link_name:
            link = lk
            break
    if link is None:
        raise ValueError(f"Link '{link_name}' not found in URDF: {urdf_path}")

    inertial = link.find('inertial')
    if inertial is None:
        raise ValueError(f"<inertial> missing for link '{link_name}'")

    m = float(inertial.find('mass').attrib['value'])

    origin = inertial.find('origin')
    if origin is not None:
        xyz = [float(v) for v in origin.attrib.get('xyz', '0 0 0').split()]
        rpy = [float(v) for v in origin.attrib.get('rpy', '0 0 0').split()]
    else:
        xyz = [0.0, 0.0, 0.0]; rpy = [0.0, 0.0, 0.0]
    cx, cy, cz = xyz
    R_li = rpy_to_R(*rpy)

    I = inertial.find('inertia').attrib
    I_in = np.array([[float(I['ixx']), float(I['ixy']), float(I['ixz'])],
                     [float(I['ixy']), float(I['iyy']), float(I['iyz'])],
                     [float(I['ixz']), float(I['iyz']), float(I['izz'])]])
    I_link = R_li @ I_in @ R_li.T
    Ixx, Ixy, Ixz = I_link[0,0], I_link[0,1], I_link[0,2]
    Iyy, Iyz, Izz = I_link[1,1], I_link[1,2], I_link[2,2]
    return np.array([m, m*cx, m*cy, m*cz, Ixx, Ixy, Ixz, Iyy, Iyz, Izz], dtype=float)

def build_full_param_vector(n_dof, per_link_params):
    a_full = np.zeros(10 * n_dof)
    for link_idx, a10 in per_link_params.items():
        s = 10*(link_idx-1); a_full[s:s+10] = np.asarray(a10).reshape(10,)
    return a_full

# ------------------------ metrics ------------------------
def regression_metrics(y, y_hat, p, has_intercept=False):
    """Return RSS, TSS, R2, R2_adj, F-stat with consistent DOF."""
    M = y.size
    residual = y - y_hat
    RSS = float(residual @ residual)
    TSS = float(((y - y.mean()) ** 2).sum()) if M > 0 else np.nan
    R2 = 1.0 - (RSS / TSS if TSS > 0 else np.nan)

    df_model = p
    df_resid = max(M - p - (1 if has_intercept else 0), 1)
    df_adj_den = max(M - (1 if has_intercept else 0), 1)

    R2_adj = 1.0 - ((RSS / df_resid) / (TSS / df_adj_den) if TSS > 0 else np.nan)
    SSR = max(TSS - RSS, 0.0)
    num = (SSR / max(df_model,1))
    den = (RSS / df_resid)
    F = (num / den) if (den > 0 and np.isfinite(num)) else np.nan
    return {"RSS": RSS, "TSS": TSS, "R2": R2, "R2_adj": R2_adj, "F": F, "M": M, "p": p}

# ------------------------ main ------------------------
def main():
    # ---- Paths & sim init ----
    root_dir = os.path.dirname(os.path.abspath(__file__))       # .../week_1_2
    conf_dir  = os.path.join(root_dir, "configs")               # .../week_1_2/configs
    conf_file = "pandaconfig.json"
    conf_path = os.path.join(conf_dir, conf_file)
    if not os.path.isfile(conf_path):
        print("[DEBUG] tried:", conf_path)
        print("[DEBUG] configs dir:", conf_dir, "exists?", os.path.isdir(conf_dir))
        raise FileNotFoundError(f"Missing {conf_file} in {conf_dir}")
    print(f"[OK] using pandaconfig: {conf_path}", flush=True)

    sim = pb.SimInterface(conf_file, conf_file_path_ext=conf_dir)

    ext_names = sim.getNameActiveJoints()
    ext_names = np.expand_dims(np.array(ext_names), axis=0)
    dyn_model = PinWrapper(conf_file, "pybullet", ext_names, ["pybullet"], False, 0, root_dir)
    n = dyn_model.getNumberofActuatedJoints()

    print("[OK] init angles:", sim.GetInitMotorAngles(), flush=True)

    # ---- Reference (use slightly different frequencies for identifiability) ----
    amplitudes  = [np.pi/4, np.pi/6, np.pi/4, np.pi/4, np.pi/4, np.pi/4, np.pi/4][:n]
    frequencies = [0.41, 0.52, 0.37, 0.43, 0.49, 0.58, 0.46][:n]
    ref = SinusoidalReference(np.array(amplitudes), np.array(frequencies), sim.GetInitMotorAngles())

    # ---- Sim params ----
    dt = sim.GetTimeStep()
    t  = 0.0
    T_max = 8.0
    print(f"[OK] dt={dt:.4f}, T_max={T_max}s, joints={n}", flush=True)

    # ---- Controller ----
    cmd = MotorCommands(); kp, kd = 1000, 100

    # ---- Buffers ----
    Y_list, tau_list, t_list = [], [], []

    # -------- data collection loop --------
    steps = 0
    while t < T_max:
        q  = sim.GetMotorAngles(0)
        qd = sim.GetMotorVelocities(0)
        qdd= sim.ComputeMotorAccelerationTMinusOne(0)

        q_d, qd_d = ref.get_values(t)
        tau_cmd = feedback_lin_ctrl(dyn_model, q, qd, q_d, qd_d, kp, kd)
        cmd.SetControlCmd(tau_cmd, ["torque"]*n)
        sim.Step(cmd, "torque")

        tau = sim.GetMotorTorques(0)
        Y_t = dyn_model.ComputeDynamicRegressor(q, qd, qdd)  # (n, 10n)

        Y_list.append(Y_t)
        tau_list.append(np.asarray(tau))
        t_list.append(t)

        t += dt; steps += 1
        if steps % 50 == 0:
            print(f"[loop] t={t:.2f}s  collected={steps}", flush=True)

    if len(Y_list) == 0:
        print("[WARN] no data collected, exit.")
        return

    # ---- drop warm-up (~1s) with protection ----
    N_warm = min(int(1.0 / max(dt, 1e-6)), max(len(Y_list) - 2, 0))
    if N_warm > 0:
        Y_list   = Y_list[N_warm:]
        tau_list = tau_list[N_warm:]
        t_list   = t_list[N_warm:]
        print(f"[OK] dropped warm-up samples: {N_warm}", flush=True)

    # =========================
    # === PART 1: only link-7 unknown (1..6 known)
    # =========================
    urdf_path = os.path.join(root_dir, "models", "panda_description", "panda.urdf")
    if not os.path.isfile(urdf_path):
        raise FileNotFoundError(f"URDF not found: {urdf_path}")
    link_names = [f"panda_link{i}" for i in range(1, 8)]

    # known params for links 1..6
    per_link_params_known = {i: extract_link10_from_urdf(urdf_path, link_names[i-1])
                             for i in range(1, min(7, n+1)) if i <= 6}
    a_known_full = build_full_param_vector(n, per_link_params_known)

    # build reduced system r = X a7
    s7, e7 = 10*(7-1), 10*(7-1)+10
    X_rows, y_rows = [], []
    for Y_t, tau_t in zip(Y_list, tau_list):
        y_t = tau_t - (Y_t @ a_known_full)   # subtract links 1..6
        X_t = Y_t[:, s7:e7]                  # link-7 columns
        X_rows.append(X_t)
        y_rows.append(y_t)
    X = np.vstack(X_rows)                    # (T*n, 10)
    y = np.hstack(y_rows)                    # (T*n,)
    condX = np.linalg.cond(X)
    lam = 1e-6 if condX < 1e6 else 1e-4
    a7_hat = np.linalg.solve(X.T @ X + lam*np.eye(10), X.T @ y)

    a7_true = extract_link10_from_urdf(urdf_path, link_names[6])
    abs_err = np.abs(a7_hat - a7_true)
    rel_err = np.where(a7_true != 0, 100*np.abs((a7_hat - a7_true)/a7_true), np.nan)

    print("\n[Part1] link-7 parameters (estimate vs truth):")
    print("  a7_hat :", np.round(a7_hat, 6))
    print("  a7_true:", np.round(a7_true, 6))
    print("  abs err:", np.round(abs_err, 6))
    print("  rel  % :", np.round(rel_err, 2))
    print(f"[diag] cond(X_link7)={condX:.3e}, ridge λ={lam}", flush=True)

    # metrics (10 free params)
    a_full_hat = a_known_full.copy(); a_full_hat[s7:e7] = a7_hat
    Y_stack   = np.vstack(Y_list)            # (T*n, 10n)
    tau_stack = np.hstack(tau_list)          # (T*n,)
    tau_pred1 = Y_stack @ a_full_hat
    mets1 = regression_metrics(tau_stack, tau_pred1, p=10, has_intercept=False)
    print("\n[Part1] metrics:")
    for k,v in mets1.items():
        print(f"  {k}: {v}")

    # plot
    uhat_t = [Y @ a_full_hat for Y in Y_list]
    tau_arr  = np.vstack(tau_list)           # (T, n)
    uhat_arr = np.vstack(uhat_t)             # (T, n)
    err_arr  = uhat_arr - tau_arr
    Tn = tau_arr.shape[0]; t_arr = np.array(t_list[:Tn])

    fig, axes = plt.subplots(n, 1, figsize=(10, 2.2*n), sharex=True)
    if n == 1: axes = [axes]
    for j in range(n):
        ax = axes[j]
        ax.plot(t_arr, tau_arr[:, j], label=f"τ{j+1} measured")
        ax.plot(t_arr, uhat_arr[:, j], linestyle="--", label=f"τ{j+1} predicted")
        ax.plot(t_arr, err_arr[:, j], linestyle=":", label=f"error τ{j+1}")
        ax.set_ylabel(f"Joint {j+1}"); ax.grid(True, alpha=0.3)
        if j == 0: ax.legend(loc="upper right", ncol=3, fontsize=8)
    axes[-1].set_xlabel("Time [s]")
    fig.suptitle("Torque prediction & error (reduced model: link 7 only)")
    out_png = os.path.join(root_dir, "part1_torque.png")
    plt.tight_layout(); plt.savefig(out_png, dpi=150)
    print(f"[OK] saved plot -> {out_png}", flush=True)

    # =========================
    # === PART 2: all links unknown (quick run)
    # =========================
    print("\n" + "="*72)
    print("PART 2: Estimating ALL links (1..7)")
    print("="*72)
    Y_all, tau_all = Y_stack, tau_stack
    M_all, P_all = Y_all.shape
    condY = np.linalg.cond(Y_all); lam_all = 1e-6 if condY < 1e6 else 1e-4
    a_hat_all = np.linalg.solve(Y_all.T @ Y_all + lam_all*np.eye(P_all), Y_all.T @ tau_all)
    tau_pred_all = Y_all @ a_hat_all
    mets_all = regression_metrics(tau_all, tau_pred_all, p=P_all, has_intercept=False)
    print(f"[diag] cond(Y_all)={condY:.3e}, ridge λ={lam_all}")
    print("[Part2] metrics:")
    for k,v in mets_all.items():
        print(f"  {k}: {v}")

    # truth compare (per link)
    a_true_all = build_full_param_vector(n, {i: extract_link10_from_urdf(urdf_path, f'panda_link{i}') for i in range(1,8)})
    abs_err_all = np.abs(a_hat_all - a_true_all)
    rel_err_all = np.where(a_true_all != 0, 100*np.abs((a_hat_all - a_true_all)/a_true_all), np.nan)
    for i in range(1,8):
        s, e = 10*(i-1), 10*i
        print(f"\n[Part2] Link {i} error:")
        print("  abs:", np.round(abs_err_all[s:e], 6))
        print("  rel%:", np.round(rel_err_all[s:e], 2))

if __name__ == '__main__':
    main()
